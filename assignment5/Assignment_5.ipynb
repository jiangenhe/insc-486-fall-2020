{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiangenhe/insc-486-fall-2021/blob/main/assignment5/Assignment_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbEshgPidmY0"
      },
      "source": [
        "# INSC486 Assignment 5 \n",
        "\n",
        "- Submit your Colab link through Canvas\n",
        "- This assignment is worth 90 points that accounts for 9% of your final grade.\n",
        "- **Code quality will be considered in grading.**\n",
        "\n",
        "Learning Objectives:\n",
        "- Logistic regression (Statistical analysis)\n",
        "- Build a supervised machine learning model (Classification)\n",
        "- Enhance your pandas skills"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-ZZtAf4UkYj"
      },
      "source": [
        "## Task 1: Poisson regression analysis (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wLpqvdiVuBt"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTUFaJ4BUti9"
      },
      "source": [
        "**Data**: https://raw.githubusercontent.com/jiangenhe/insc-486-fall-2021/main/assignment5/poisson_sim.csv\n",
        "\n",
        "**num_awards** is the outcome variable and indicates the number of awards earned by students at a high school in a year, **math** is a continuous predictor variable and represents students’ scores on their math final exam, and **prog** is a categorical predictor variable with three levels indicating the type of program in which the students were enrolled. It is coded as 1 = “General”, 2 = “Academic” and 3 = “Vocational”. Let’s start with loading the data and looking at some descriptive statistics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1p-TvkjWAjd"
      },
      "source": [
        "### 1. Perform a Poisson regression analaysis to predict the number of awards earned by students at one high school. \n",
        "\n",
        "Predictors of the number of awards earned include the type of program in which the student was enrolled (e.g., vocational, general or academic) and the score on their final exam in math."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvIC7qMYXJEy"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULCDlmBaXJgk"
      },
      "source": [
        "### 2. Interpret the regression results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX8UwUmrXRg-"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzmMScd1sh_w"
      },
      "source": [
        "## Task 3: Classification Playspace (40%)\n",
        "\n",
        "For this task, you will build classifiers to classify an iris species as either (virginica, setosa, or versicolor) for the iris flower dataset. You will use different machine learning algorithm to build the classifiers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oftnB-oOpesk"
      },
      "source": [
        "### 0. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvlM9euBn85j"
      },
      "source": [
        "import seaborn as sns\n",
        "iris = sns.load_dataset(\"iris\")\n",
        "\n",
        "# X = feature values, all the columns except the last column\n",
        "X = iris.iloc[:, :-1]\n",
        "\n",
        "# y = target values, last column of the data frame\n",
        "y = iris.iloc[:, -1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA70Sl8Mrbar"
      },
      "source": [
        "### 1. Build a Basic Understanding of the dataset\n",
        "\n",
        "Use head(), describe() and any other pandas features to explore the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qivOFPALr9J4"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG80-gyCrf3w"
      },
      "source": [
        "### 2. Visualize the Dataset\n",
        "Read the code and run it. You don't need to make any change."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVY0m-JjsT6Q"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Species')\n",
        "\n",
        "pltX = iris.loc[:, 'sepal_length']\n",
        "pltY = iris.loc[:,'species']\n",
        "plt.scatter(pltX, pltY, color='blue', label='sepal_length')\n",
        "\n",
        "pltX = iris.loc[:, 'sepal_width']\n",
        "pltY = iris.loc[:,'species']\n",
        "plt.scatter(pltX, pltY, color='green', label='sepal_width')\n",
        "\n",
        "pltX = iris.loc[:, 'petal_length']\n",
        "pltY = iris.loc[:,'species']\n",
        "plt.scatter(pltX, pltY, color='red', label='petal_length')\n",
        "\n",
        "pltX = iris.loc[:, 'petal_width']\n",
        "pltY = iris.loc[:,'species']\n",
        "plt.scatter(pltX, pltY, color='black', label='petal_width')\n",
        "\n",
        "plt.legend(loc=4, prop={'size':8})\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBh1We45u88-"
      },
      "source": [
        "**For question 3 - 6, you are feel to set hyperparameters that you think is reasonable.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT_b-HSGtGrK"
      },
      "source": [
        "### 3. Use kNN to build a classifier, including train/test data split, fit, and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nOziStQtqIO"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5R0t29rt2p8"
      },
      "source": [
        "### 4. Use logistic model to build a classifier, including train/test data split, fit, and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjwSGi2St-L5"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRn32_H4t_pZ"
      },
      "source": [
        "### 5. Use SVM to build a classifier, including train/test data split, fit, and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wemFEkeuWOx"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpigAbATuYo0"
      },
      "source": [
        "### 6. Use Decision Tree Model to build a classifier, including train/test data split, fit, and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uSEx_Dgujzd"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BhhUIKZuvB7"
      },
      "source": [
        "### 7. Select one of the models to set different hyperparameters to compare the performace difference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XotBM2VXvrXq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG0_ENtKuu-H"
      },
      "source": [
        "### 8. Select one of the models to apply cross validataion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbOcIO41v9Wt"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIRPHhaFWAhu"
      },
      "source": [
        "## Task 3: Evaluation (50%)\n",
        "\n",
        "In this task you will train several models and evaluate how effectively they predict instances of fraud using data based on [this dataset from Kaggle](https://www.kaggle.com/mlg-ulb/creditcardfraud). \n",
        " \n",
        "Each row in `fraud_data.csv` corresponds to a credit card transaction. Features include confidential variables `V1` through `V28` as well as `Amount` which is the amount of the transaction. \n",
        " \n",
        "The target is stored in the `class` column, where a value of 1 corresponds to an instance of fraud and 0 corresponds to an instance of not fraud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "RSyO-kxUWAhv"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrOfPrpnWAhv"
      },
      "source": [
        "### Question 1\n",
        "Import the data from `fraud_data.csv`. What percentage of the observations in the dataset are instances of fraud?\n",
        "\n",
        "*The result should be a float between 0 and 1.* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "DQZ2dNEBWAhw"
      },
      "source": [
        "# Use X_train, X_test, y_train, y_test for all of the following questions\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/jiangenhe/insc-486-fall-2021/main/assignment5/fraud_data.txt')\n",
        "\n",
        "X = df.iloc[:,:-1]\n",
        "y = df.iloc[:,-1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v4-i7L7Wrc0"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-R5W6q9WAhw"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "Using `X_train`, `X_test`, `y_train`, and `y_test` (as defined above), train a dummy classifier that classifies everything as the majority class of the training data. What is the accuracy of this classifier? What is the recall?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "mmOEdC4sWAhw"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import recall_score\n",
        "    \n",
        "# Your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuWU1LDJWAhx"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "Using X_train, X_test, y_train, y_test (as defined above), train a SVC classifer using the default parameters. What is the accuracy, recall, and precision of this classifier?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "LasLHyN8WAhx"
      },
      "source": [
        "from sklearn.metrics import recall_score, precision_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kCfLhrSWAhx"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "Using the SVC classifier with parameters `{'C': 1e9, 'gamma': 1e-07}`, what is the confusion matrix when using a threshold of -220 on the decision function. Use X_test and y_test.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "zv2UaAyvWAhx"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc0NER93WAhy"
      },
      "source": [
        "### Question 5\n",
        "\n",
        "Train a logisitic regression classifier with default parameters using X_train and y_train.\n",
        "\n",
        "For the logisitic regression classifier, create a precision recall curve and a roc curve using y_test and the probability estimates for X_test (probability it is fraud).\n",
        "\n",
        "Looking at the precision recall curve, what is the recall when the precision is `0.75`?\n",
        "\n",
        "Looking at the roc curve, what is the true positive rate when the false positive rate is `0.16`?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "objoqZAEWAhy"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}